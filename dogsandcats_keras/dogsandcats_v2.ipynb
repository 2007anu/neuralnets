{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#path = \"../data/dogsandcats_small/\" # we copied a fraction of the full set for tests\n",
    "path = \"../data/dogsandcats/\"\n",
    "model_path = path + \"models/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 3000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "val_batches = get_batches('valid', shuffle=False, batch_size=batch_size) # no shuffle as we store conv output\n",
    "trn_batches = get_batches('train', shuffle=False, batch_size=batch_size) # no shuffle as we store conv output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat/cat.3044.jpg',\n",
       " 'cat/cat.8847.jpg',\n",
       " 'cat/cat.308.jpg',\n",
       " 'cat/cat.10802.jpg',\n",
       " 'cat/cat.5060.jpg',\n",
       " 'cat/cat.10406.jpg',\n",
       " 'cat/cat.11054.jpg',\n",
       " 'cat/cat.380.jpg',\n",
       " 'cat/cat.6588.jpg',\n",
       " 'cat/cat.9693.jpg']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batches.filenames[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_labels = onehot(val_batches.classes)\n",
    "trn_labels = onehot(trn_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DONT USE IT FOR NOW\n",
    "if False:\n",
    "    realvgg = Vgg16()\n",
    "    conv_layers, fc_layers = split_at(realvgg.model, Convolution2D)\n",
    "    conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 224, 224)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "vggbase = Vgg16()\n",
    "vggbase.model.pop()\n",
    "vggbase.model.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will take 1 or 2 minutes to complete the 1st time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DONT USE IT FOR NOW\n",
    "if False:\n",
    "    try:\n",
    "        val_features = load_array(model_path+'valid_convlayer_features.bc')\n",
    "        if False: # force update\n",
    "            raise\n",
    "    except:\n",
    "        print('Missing file')\n",
    "        val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "        save_array(model_path + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    val_vggfeatures = load_array(model_path+'valid_vggbase_features.bc')\n",
    "    if False: # force update\n",
    "        raise\n",
    "except:\n",
    "    print('Missing file')\n",
    "    val_vggfeatures = vggbase.model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "    save_array(model_path + 'valid_vggbase_features.bc', val_vggfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will take a few minutes (maybe 10) to complete the 1st time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DONT USE IT FOR NOW\n",
    "if False:\n",
    "    try:\n",
    "        trn_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "        if False: # force update\n",
    "            raise\n",
    "    except:\n",
    "        print('Missing file')\n",
    "        trn_features = conv_model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "        save_array(model_path + 'train_convlayer_features.bc', trn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trn_vggfeatures = load_array(model_path+'train_vggbase_features.bc')\n",
    "    if False: # force update\n",
    "        raise\n",
    "except:\n",
    "    print('Missing file')\n",
    "    trn_vggfeatures = vggbase.model.predict_generator(trn_batches, trn_batches.nb_sample)\n",
    "    save_array(model_path + 'train_vggbase_features.bc', trn_vggfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_layers = [BatchNormalization(input_shape=(4096,)),\n",
    "             Dropout(0.25),\n",
    "             Dense(2, activation='softmax')]\n",
    "ll_model = Sequential(ll_layers)\n",
    "ll_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 3000 samples\n",
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 0s - loss: 0.2221 - acc: 0.9093 - val_loss: 0.1989 - val_acc: 0.9270\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 0s - loss: 0.2220 - acc: 0.9137 - val_loss: 0.1984 - val_acc: 0.9280\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 0s - loss: 0.2248 - acc: 0.9103 - val_loss: 0.1984 - val_acc: 0.9277\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 0s - loss: 0.2263 - acc: 0.9137 - val_loss: 0.1978 - val_acc: 0.9267\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 0s - loss: 0.2266 - acc: 0.9087 - val_loss: 0.1979 - val_acc: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca6c941b90>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll_model.optimizer.lr = 10*1e-5\n",
    "ll_model.fit(trn_vggfeatures, trn_labels, validation_data=(val_vggfeatures, val_labels), nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ll_model.save_weights(model_path+'llmodel_finetune1.h5')\n",
    "#ll_model.load_weights(model_path+'llmodel_finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test/10916.jpg',\n",
       " 'test/12374.jpg',\n",
       " 'test/1871.jpg',\n",
       " 'test/6164.jpg',\n",
       " 'test/3491.jpg',\n",
       " 'test/8027.jpg',\n",
       " 'test/1556.jpg',\n",
       " 'test/6560.jpg',\n",
       " 'test/8180.jpg',\n",
       " 'test/7451.jpg']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches = get_batches('test', shuffle=False, batch_size=batch_size, class_mode=None)\n",
    "testfiles = test_batches.filenames\n",
    "testfiles[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will take a few minutes (maybe 5) to complete the 1st time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_vggfeatures = load_array(model_path+'test_vggbase_features.bc')\n",
    "    if False: # force update\n",
    "        raise\n",
    "except:\n",
    "    print('Missing file')\n",
    "    test_vggfeatures = vggbase.model.predict_generator(test_batches, test_batches.nb_sample)\n",
    "    save_array(model_path + 'test_vggbase_features.bc', test_vggfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_preds = ll_model.predict_on_batch(test_vggfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-8abf359cec12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m12500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(test_preds) == 12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.453 ,  0.547 ],\n",
       "       [ 0.5199,  0.4801],\n",
       "       [ 0.7576,  0.2424],\n",
       "       [ 0.0066,  0.9934],\n",
       "       [ 0.7282,  0.2718],\n",
       "       [ 0.9167,  0.0833],\n",
       "       [ 0.434 ,  0.566 ],\n",
       "       [ 0.9562,  0.0438],\n",
       "       [ 0.8702,  0.1298],\n",
       "       [ 0.3122,  0.6878]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'label': 0.99986},\n",
       " {'id': 2, 'label': 0.9999},\n",
       " {'id': 3, 'label': 0.9999},\n",
       " {'id': 4, 'label': 0.99985},\n",
       " {'id': 5, 'label': 0.0001},\n",
       " {'id': 6, 'label': 0.00019},\n",
       " {'id': 7, 'label': 0.0001},\n",
       " {'id': 8, 'label': 0.0001},\n",
       " {'id': 9, 'label': 0.00055},\n",
       " {'id': 10, 'label': 0.0001},\n",
       " {'id': 11, 'label': 0.0001},\n",
       " {'id': 12, 'label': 0.99988},\n",
       " {'id': 13, 'label': 0.00523},\n",
       " {'id': 14, 'label': 0.00335},\n",
       " {'id': 15, 'label': 0.0001},\n",
       " {'id': 16, 'label': 0.00025},\n",
       " {'id': 17, 'label': 0.9506},\n",
       " {'id': 18, 'label': 0.9999}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_idx = 1\n",
    "Z1 = [{'id':int(f.split('/')[-1].split('.')[0]), 'label':min(max(round(p[dog_idx],5),0.0001),0.9999)} \n",
    "      for f, p in zip(testfiles, test_preds)]\n",
    "def comp(x,y):\n",
    "    return int(x['id']) - int(y['id'])\n",
    "Z1 = sorted(Z1, comp)\n",
    "Z1[0:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "        \n",
    "with open('predictions.csv', 'w') as csvfile:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for z in Z1:\n",
    "        writer.writerow(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
