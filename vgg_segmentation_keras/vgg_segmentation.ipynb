{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        if False:\n",
    "            # first version I tried\n",
    "            L.append( ZeroPadding2D((1, 1)) )\n",
    "            L.append( Convolution2D(cdim, 3, 3, activation='relu', name=convname) )\n",
    "        else:\n",
    "            L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) )\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vgg16_blank():\n",
    "    \n",
    "    withDO = True # no effect during evaluation but usefull for fine-tuning\n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        mdl.add( Permute((1,2,3), input_shape=(3,224,224)) ) # WARNING : 0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        mdl.add( Convolution2D(4096, 7, 7, activation='relu', name='fc6') )\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        mdl.add( Convolution2D(4096, 1, 1, activation='relu', name='fc7') )\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        # WARNING : model decapitation, remove the classifier step\n",
    "        #mdl.add( Convolution2D(2622, 1, 1, name='fc8') )\n",
    "        #mdl.add( Flatten() )\n",
    "        #mdl.add( Activation('softmax') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        # See following link for a version based on Keras functional API :\n",
    "        # gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segmentmodel = vgg16_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#segmentmodel.summary() # visual inspection of model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG weigths from .mat file\n",
    "\n",
    "#### https://www.vlfeat.org/matconvnet/pretrained/#semantic-segmentation\n",
    "##### Download from console with :\n",
    "wget https://www.vlfeat.org/matconvnet/models/pascal-fcn16s-dag.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    data = loadmat('pascal-fcn16s-dag.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    l = data['layers']\n",
    "    p = data['params']\n",
    "    description = data['meta'][0,0].classes[0,0].description\n",
    "else:\n",
    "    raise ValueError('not implemented yet')\n",
    "    data = loadmat('vgg_face_matconvnet/data/vgg_face.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    net = data['net'][0,0]\n",
    "    l = net.layers\n",
    "    description = net.classes[0,0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 42), (1, 38), (1, 21))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape, p.shape, description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'conv1_1_filter', (3, 3, 3, 64), u'conv1_1_bias', (64, 1))\n",
      "(u'conv1_2_filter', (3, 3, 64, 64), u'conv1_2_bias', (64, 1))\n",
      "(u'conv2_1_filter', (3, 3, 64, 128), u'conv2_1_bias', (128, 1))\n",
      "(u'conv2_2_filter', (3, 3, 128, 128), u'conv2_2_bias', (128, 1))\n",
      "(u'conv3_1_filter', (3, 3, 128, 256), u'conv3_1_bias', (256, 1))\n",
      "(u'conv3_2_filter', (3, 3, 256, 256), u'conv3_2_bias', (256, 1))\n",
      "(u'conv3_3_filter', (3, 3, 256, 256), u'conv3_3_bias', (256, 1))\n",
      "(u'conv4_1_filter', (3, 3, 256, 512), u'conv4_1_bias', (512, 1))\n",
      "(u'conv4_2_filter', (3, 3, 512, 512), u'conv4_2_bias', (512, 1))\n",
      "(u'conv4_3_filter', (3, 3, 512, 512), u'conv4_3_bias', (512, 1))\n",
      "(u'conv5_1_filter', (3, 3, 512, 512), u'conv5_1_bias', (512, 1))\n",
      "(u'conv5_2_filter', (3, 3, 512, 512), u'conv5_2_bias', (512, 1))\n",
      "(u'conv5_3_filter', (3, 3, 512, 512), u'conv5_3_bias', (512, 1))\n",
      "(u'fc6_filter', (7, 7, 512, 4096), u'fc6_bias', (4096, 1))\n",
      "(u'fc7_filter', (1, 1, 4096, 4096), u'fc7_bias', (4096, 1))\n",
      "(u'score_fr_filter', (1, 1, 4096, 21), u'score_fr_bias', (21, 1))\n",
      "(u'score2_filter', (4, 4, 21, 21), u'score2_bias', (21, 1))\n",
      "(u'score_pool4_filter', (1, 1, 512, 21), u'score_pool4_bias', (21, 1))\n",
      "(u'upsample_new_filter', (32, 32, 21, 21), u'upsample_new_bias', (21, 1))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, p.shape[1]-1, 2):\n",
    "    print(p[0,i].name[0], p[0,i].value.shape, p[0,i+1].name[0], p[0,i+1].value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1_1', 'dagnn.Conv', ['data'], ['conv1_1'])\n",
      "('relu1_1', 'dagnn.ReLU', ['conv1_1'], ['conv1_1x'])\n",
      "('conv1_2', 'dagnn.Conv', ['conv1_1x'], ['conv1_2'])\n",
      "('relu1_2', 'dagnn.ReLU', ['conv1_2'], ['conv1_2x'])\n",
      "('pool1', 'dagnn.Pooling', ['conv1_2x'], ['pool1'])\n",
      "('conv2_1', 'dagnn.Conv', ['pool1'], ['conv2_1'])\n",
      "('relu2_1', 'dagnn.ReLU', ['conv2_1'], ['conv2_1x'])\n",
      "('conv2_2', 'dagnn.Conv', ['conv2_1x'], ['conv2_2'])\n",
      "('relu2_2', 'dagnn.ReLU', ['conv2_2'], ['conv2_2x'])\n",
      "('pool2', 'dagnn.Pooling', ['conv2_2x'], ['pool2'])\n",
      "('conv3_1', 'dagnn.Conv', ['pool2'], ['conv3_1'])\n",
      "('relu3_1', 'dagnn.ReLU', ['conv3_1'], ['conv3_1x'])\n",
      "('conv3_2', 'dagnn.Conv', ['conv3_1x'], ['conv3_2'])\n",
      "('relu3_2', 'dagnn.ReLU', ['conv3_2'], ['conv3_2x'])\n",
      "('conv3_3', 'dagnn.Conv', ['conv3_2x'], ['conv3_3'])\n",
      "('relu3_3', 'dagnn.ReLU', ['conv3_3'], ['conv3_3x'])\n",
      "('pool3', 'dagnn.Pooling', ['conv3_3x'], ['pool3'])\n",
      "('conv4_1', 'dagnn.Conv', ['pool3'], ['conv4_1'])\n",
      "('relu4_1', 'dagnn.ReLU', ['conv4_1'], ['conv4_1x'])\n",
      "('conv4_2', 'dagnn.Conv', ['conv4_1x'], ['conv4_2'])\n",
      "('relu4_2', 'dagnn.ReLU', ['conv4_2'], ['conv4_2x'])\n",
      "('conv4_3', 'dagnn.Conv', ['conv4_2x'], ['conv4_3'])\n",
      "('relu4_3', 'dagnn.ReLU', ['conv4_3'], ['conv4_3x'])\n",
      "('pool4', 'dagnn.Pooling', ['conv4_3x'], ['pool4'])\n",
      "('conv5_1', 'dagnn.Conv', ['pool4'], ['conv5_1'])\n",
      "('relu5_1', 'dagnn.ReLU', ['conv5_1'], ['conv5_1x'])\n",
      "('conv5_2', 'dagnn.Conv', ['conv5_1x'], ['conv5_2'])\n",
      "('relu5_2', 'dagnn.ReLU', ['conv5_2'], ['conv5_2x'])\n",
      "('conv5_3', 'dagnn.Conv', ['conv5_2x'], ['conv5_3'])\n",
      "('relu5_3', 'dagnn.ReLU', ['conv5_3'], ['conv5_3x'])\n",
      "('pool5', 'dagnn.Pooling', ['conv5_3x'], ['pool5'])\n",
      "('fc6', 'dagnn.Conv', ['pool5'], ['fc6'])\n",
      "('relu6', 'dagnn.ReLU', ['fc6'], ['fc6x'])\n",
      "('fc7', 'dagnn.Conv', ['fc6x'], ['fc7'])\n",
      "('relu7', 'dagnn.ReLU', ['fc7'], ['fc7x'])\n",
      "('score_fr', 'dagnn.Conv', ['fc7x'], ['score'])\n",
      "('score2', 'dagnn.ConvTranspose', ['score'], ['score2'])\n",
      "('score_pool4', 'dagnn.Conv', ['pool4'], ['score_pool4'])\n",
      "('crop', 'dagnn.Crop', ['score_pool4', 'score2'], ['score_pool4c'])\n",
      "('fuse', 'dagnn.Sum', ['score2', 'score_pool4c'], ['score_fused'])\n",
      "('upsample_new', 'dagnn.ConvTranspose', ['score_fused'], ['bigscore'])\n",
      "('cropx', 'dagnn.Crop', ['bigscore', 'data'], ['upscore'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(l.shape[1]):\n",
    "    print(str(l[0,i].name[0]), str(l[0,i].type[0]),\n",
    "          [str(n[0]) for n in l[0,i].inputs[0,:]],\n",
    "          [str(n[0]) for n in l[0,i].outputs[0,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Convolutional Networks for Semantic Segmentation\n",
    "##### Jonathan Long, Evan Shelhamer, Trevor Darrell\n",
    "\n",
    "www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf\n",
    "\n",
    "Extract from the article relating to the model architecture.\n",
    "\n",
    "The model is derived from VGG16.\n",
    "\n",
    "**remark** : deconvolution and conv-transpose are synonyms, they perform up-sampling\n",
    "\n",
    "#### 4.1. From classifier to dense FCN\n",
    "\n",
    "We decapitate each net by discarding the final classifier layer [**code comment** : *this is why fc8 is not included*], and convert all fully connected layers to convolutions.\n",
    "\n",
    "We append a 1 × 1 convolution with channel dimension 21 [**code comment** : *layer named score_fr_filter*] to predict scores for each of the PASCAL classes (including background) at each of the coarse output locations, followed by a deconvolution layer to bilinearly upsample the coarse outputs to pixel-dense outputs as described in Section 3.3.\n",
    "\n",
    "\n",
    "#### 4.2. Combining what and where\n",
    "We define a new fully convolutional net (FCN) for segmentation that combines layers of the feature hierarchy and\n",
    "refines the spatial precision of the output. See Figure 3. While fully convolutionalized classifiers can be fine-\n",
    "tuned to segmentation as shown in 4.1, and even score highly on the standard metric, their output is dissatisfyingly\n",
    "coarse (see Figure 4). The 32 pixel stride at the final prediction layer limits the scale of detail in the upsampled output.\n",
    "\n",
    "We address this by adding skips that combine the final prediction layer with lower layers with finer strides. This turns a line topology into a DAG [**code comment** : *this is why some latter stage layers have 2 inputs*], with edges that skip ahead from lower layers to higher ones (Figure 3). As they\n",
    "see fewer pixels, the finer scale predictions should need fewer layers, so it makes sense to make them from shallower\n",
    "net outputs. Combining fine layers and coarse layers lets the model make local predictions that respect global structure.\n",
    "\n",
    "We first divide the output stride in half by predicting from a 16 pixel stride layer. We add a 1 × 1 convolution\n",
    "layer on top of pool4 [**code comment** : *the score_pool4_filter layer*] to produce additional class predictions. We fuse this output with the predictions computed\n",
    "on top of conv7 (convolutionalized fc7) at stride 32 by adding a 2× upsampling layer and summing both predictions\n",
    "(see Figure 3). We initialize the 2x upsampling to bilinear interpolation, but allow the parameters to be learned\n",
    "as described in Section 3.3. Finally, the stride 16 predictions are upsampled back to the image. We call this net\n",
    "FCN-16s. FCN-16s is learned end-to-end, initialized with the parameters of the last, coarser net, which we now call\n",
    "FCN-32s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : adapt this function\n",
    "def weight_compare(kmodel):\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    prmt = (3,2,0,1) # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        mattype = l[0,i][0,0].type[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            print matname, mattype\n",
    "            print l[0,i][0,0].weights[0,0].transpose(prmt).shape, l[0,i][0,0].weights[0,1].shape\n",
    "            print kmodel.layers[kindex].get_weights()[0].shape, kmodel.layers[kindex].get_weights()[1].shape\n",
    "            print '------------------------------------------'\n",
    "        else:\n",
    "            print 'MISSING : ', matname, mattype\n",
    "            print '------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weight_compare(segmentmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : adapt this function\n",
    "def copy_mat_to_keras(kmodel):\n",
    "\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    prmt = (3,2,0,1) # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            #print matname\n",
    "            l_weights = l[0,i][0,0].weights[0,0]\n",
    "            l_bias = l[0,i][0,0].weights[0,1]\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            f_l_weights = np.flip(f_l_weights, 2)\n",
    "            f_l_weights = np.flip(f_l_weights, 3)\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])\n",
    "            #print '------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy_mat_to_keras(segmentmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
