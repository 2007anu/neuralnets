{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Deconvolution2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        if False:\n",
    "            # first version I tried\n",
    "            L.append( ZeroPadding2D((1, 1)) )\n",
    "            L.append( Convolution2D(cdim, 3, 3, activation='relu', name=convname) )\n",
    "        else:\n",
    "            L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) )\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vgg16_blank():\n",
    "    \n",
    "    withDO = False # no effect during evaluation but usefull for fine-tuning\n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        #mdl.add( Permute((1,2,3), input_shape=(3,224,224)) ) # WARNING : 0 is the sample dim\n",
    "        mdl.add( Permute((1,2,3), input_shape=(3,512,512)) ) # WARNING : 0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        mdl.add( Convolution2D(4096, 7, 7, border_mode='same', activation='relu', name='fc6') ) # WARNING border\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        mdl.add( Convolution2D(4096, 1, 1, border_mode='same', activation='relu', name='fc7') ) # WARNING border\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        # WARNING : model decapitation, remove the classifier step\n",
    "        #mdl.add( Convolution2D(2622, 1, 1, name='fc8') )\n",
    "        #mdl.add( Flatten() )\n",
    "        #mdl.add( Activation('softmax') )\n",
    "        \n",
    "        mdl.add( Convolution2D(21, 1, 1, activation='relu', name='score_fr') )\n",
    "        \n",
    "        mdl.add( Deconvolution2D(21, 4, 4, # WARNING : exact meaning ?\n",
    "                                   output_shape=(None, 21, 32, 32), # WARNING : exact meaning ?\n",
    "                                   border_mode='same', # WARNING : zero or same ?\n",
    "                                   subsample=(1, 1), # WARNING : exact meaning ?\n",
    "                                   activation=None,\n",
    "                                    name = 'score2') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        # See following link for a version based on Keras functional API :\n",
    "        # gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?? Deconvolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segmentmodel = vgg16_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to replicate MatConvNet.DAGN.Sum layer\n",
    "# documentation : https://keras.io/getting-started/sequential-model-guide/\n",
    "from keras.layers import merge\n",
    "summed = merge([segmentmodel.layers[-4].output, segmentmodel.layers[-3].output], mode='sum')\n",
    "mdlsum = Model(segmentmodel.input, summed)\n",
    "#mdlsum.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "permute_10 (Permute)             (None, 3, 512, 512)   0           permute_input_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Convolution2D)          (None, 64, 512, 512)  1792        permute_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Convolution2D)          (None, 64, 512, 512)  36928       conv1_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_46 (MaxPooling2D)   (None, 64, 256, 256)  0           conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Convolution2D)          (None, 128, 256, 256) 73856       maxpooling2d_46[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Convolution2D)          (None, 128, 256, 256) 147584      conv2_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_47 (MaxPooling2D)   (None, 128, 128, 128) 0           conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Convolution2D)          (None, 256, 128, 128) 295168      maxpooling2d_47[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Convolution2D)          (None, 256, 128, 128) 590080      conv3_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3 (Convolution2D)          (None, 256, 128, 128) 590080      conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_48 (MaxPooling2D)   (None, 256, 64, 64)   0           conv3_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Convolution2D)          (None, 512, 64, 64)   1180160     maxpooling2d_48[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Convolution2D)          (None, 512, 64, 64)   2359808     conv4_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3 (Convolution2D)          (None, 512, 64, 64)   2359808     conv4_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_49 (MaxPooling2D)   (None, 512, 32, 32)   0           conv4_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Convolution2D)          (None, 512, 32, 32)   2359808     maxpooling2d_49[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Convolution2D)          (None, 512, 32, 32)   2359808     conv5_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3 (Convolution2D)          (None, 512, 32, 32)   2359808     conv5_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_50 (MaxPooling2D)   (None, 512, 16, 16)   0           conv5_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc6 (Convolution2D)              (None, 4096, 16, 16)  102764544   maxpooling2d_50[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "fc7 (Convolution2D)              (None, 4096, 16, 16)  16781312    fc6[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "score_fr (Convolution2D)         (None, 21, 16, 16)    86037       fc7[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "score2 (Deconvolution2D)         (None, 21, 32, 32)    7077        score_fr[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 134,353,658\n",
      "Trainable params: 134,353,658\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "segmentmodel.summary() # visual inspection of model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG weigths from .mat file\n",
    "\n",
    "#### https://www.vlfeat.org/matconvnet/pretrained/#semantic-segmentation\n",
    "##### Download from console with :\n",
    "wget https://www.vlfeat.org/matconvnet/models/pascal-fcn16s-dag.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    data = loadmat('pascal-fcn16s-dag.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    l = data['layers']\n",
    "    p = data['params']\n",
    "    description = data['meta'][0,0].classes[0,0].description\n",
    "else:\n",
    "    raise ValueError('not implemented yet')\n",
    "    data = loadmat('vgg_face_matconvnet/data/vgg_face.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    net = data['net'][0,0]\n",
    "    l = net.layers\n",
    "    description = net.classes[0,0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 42), (1, 38), (1, 21))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape, p.shape, description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_fieldnames', 'dilate', 'hasBias', 'opts', 'pad', 'size', 'stride']\n",
      "[[1]]\n",
      "[[   7    7  512 4096]]\n",
      "[[0 0 0 0]]\n",
      "[[1 1]]\n",
      "[[1 1]]\n"
     ]
    }
   ],
   "source": [
    "#l[0,21].block[0,0], l[0,21].params\n",
    "#print(l[0,36])\n",
    "print(dir(l[0,33].block[0,0]))\n",
    "lnb = 31 #36\n",
    "#print(l[0,lnb].block[0,0].upsample)\n",
    "#print(l[0,lnb].block[0,0].crop)\n",
    "print(l[0,lnb].block[0,0].hasBias)\n",
    "#print(l[0,lnb].block[0,0].numGroups)\n",
    "print(l[0,lnb].block[0,0].size)\n",
    "#print(l[0,lnb].block[0,0].opts)\n",
    "print(l[0,lnb].block[0,0].pad)\n",
    "print(l[0,lnb].block[0,0].stride)\n",
    "print(l[0,lnb].block[0,0].dilate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'conv1_1_filter', (3, 3, 3, 64), u'conv1_1_bias', (64, 1))\n",
      "(2, u'conv1_2_filter', (3, 3, 64, 64), u'conv1_2_bias', (64, 1))\n",
      "(4, u'conv2_1_filter', (3, 3, 64, 128), u'conv2_1_bias', (128, 1))\n",
      "(6, u'conv2_2_filter', (3, 3, 128, 128), u'conv2_2_bias', (128, 1))\n",
      "(8, u'conv3_1_filter', (3, 3, 128, 256), u'conv3_1_bias', (256, 1))\n",
      "(10, u'conv3_2_filter', (3, 3, 256, 256), u'conv3_2_bias', (256, 1))\n",
      "(12, u'conv3_3_filter', (3, 3, 256, 256), u'conv3_3_bias', (256, 1))\n",
      "(14, u'conv4_1_filter', (3, 3, 256, 512), u'conv4_1_bias', (512, 1))\n",
      "(16, u'conv4_2_filter', (3, 3, 512, 512), u'conv4_2_bias', (512, 1))\n",
      "(18, u'conv4_3_filter', (3, 3, 512, 512), u'conv4_3_bias', (512, 1))\n",
      "(20, u'conv5_1_filter', (3, 3, 512, 512), u'conv5_1_bias', (512, 1))\n",
      "(22, u'conv5_2_filter', (3, 3, 512, 512), u'conv5_2_bias', (512, 1))\n",
      "(24, u'conv5_3_filter', (3, 3, 512, 512), u'conv5_3_bias', (512, 1))\n",
      "(26, u'fc6_filter', (7, 7, 512, 4096), u'fc6_bias', (4096, 1))\n",
      "(28, u'fc7_filter', (1, 1, 4096, 4096), u'fc7_bias', (4096, 1))\n",
      "(30, u'score_fr_filter', (1, 1, 4096, 21), u'score_fr_bias', (21, 1))\n",
      "(32, u'score2_filter', (4, 4, 21, 21), u'score2_bias', (21, 1))\n",
      "(34, u'score_pool4_filter', (1, 1, 512, 21), u'score_pool4_bias', (21, 1))\n",
      "(36, u'upsample_new_filter', (32, 32, 21, 21), u'upsample_new_bias', (21, 1))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, p.shape[1]-1, 2):\n",
    "    print(i, p[0,i].name[0], p[0,i].value.shape, p[0,i+1].name[0], p[0,i+1].value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'conv1_1', 'dagnn.Conv', ['data'], ['conv1_1'])\n",
      "(1, 'relu1_1', 'dagnn.ReLU', ['conv1_1'], ['conv1_1x'])\n",
      "(2, 'conv1_2', 'dagnn.Conv', ['conv1_1x'], ['conv1_2'])\n",
      "(3, 'relu1_2', 'dagnn.ReLU', ['conv1_2'], ['conv1_2x'])\n",
      "(4, 'pool1', 'dagnn.Pooling', ['conv1_2x'], ['pool1'])\n",
      "(5, 'conv2_1', 'dagnn.Conv', ['pool1'], ['conv2_1'])\n",
      "(6, 'relu2_1', 'dagnn.ReLU', ['conv2_1'], ['conv2_1x'])\n",
      "(7, 'conv2_2', 'dagnn.Conv', ['conv2_1x'], ['conv2_2'])\n",
      "(8, 'relu2_2', 'dagnn.ReLU', ['conv2_2'], ['conv2_2x'])\n",
      "(9, 'pool2', 'dagnn.Pooling', ['conv2_2x'], ['pool2'])\n",
      "(10, 'conv3_1', 'dagnn.Conv', ['pool2'], ['conv3_1'])\n",
      "(11, 'relu3_1', 'dagnn.ReLU', ['conv3_1'], ['conv3_1x'])\n",
      "(12, 'conv3_2', 'dagnn.Conv', ['conv3_1x'], ['conv3_2'])\n",
      "(13, 'relu3_2', 'dagnn.ReLU', ['conv3_2'], ['conv3_2x'])\n",
      "(14, 'conv3_3', 'dagnn.Conv', ['conv3_2x'], ['conv3_3'])\n",
      "(15, 'relu3_3', 'dagnn.ReLU', ['conv3_3'], ['conv3_3x'])\n",
      "(16, 'pool3', 'dagnn.Pooling', ['conv3_3x'], ['pool3'])\n",
      "(17, 'conv4_1', 'dagnn.Conv', ['pool3'], ['conv4_1'])\n",
      "(18, 'relu4_1', 'dagnn.ReLU', ['conv4_1'], ['conv4_1x'])\n",
      "(19, 'conv4_2', 'dagnn.Conv', ['conv4_1x'], ['conv4_2'])\n",
      "(20, 'relu4_2', 'dagnn.ReLU', ['conv4_2'], ['conv4_2x'])\n",
      "(21, 'conv4_3', 'dagnn.Conv', ['conv4_2x'], ['conv4_3'])\n",
      "(22, 'relu4_3', 'dagnn.ReLU', ['conv4_3'], ['conv4_3x'])\n",
      "(23, 'pool4', 'dagnn.Pooling', ['conv4_3x'], ['pool4'])\n",
      "(24, 'conv5_1', 'dagnn.Conv', ['pool4'], ['conv5_1'])\n",
      "(25, 'relu5_1', 'dagnn.ReLU', ['conv5_1'], ['conv5_1x'])\n",
      "(26, 'conv5_2', 'dagnn.Conv', ['conv5_1x'], ['conv5_2'])\n",
      "(27, 'relu5_2', 'dagnn.ReLU', ['conv5_2'], ['conv5_2x'])\n",
      "(28, 'conv5_3', 'dagnn.Conv', ['conv5_2x'], ['conv5_3'])\n",
      "(29, 'relu5_3', 'dagnn.ReLU', ['conv5_3'], ['conv5_3x'])\n",
      "(30, 'pool5', 'dagnn.Pooling', ['conv5_3x'], ['pool5'])\n",
      "(31, 'fc6', 'dagnn.Conv', ['pool5'], ['fc6'])\n",
      "(32, 'relu6', 'dagnn.ReLU', ['fc6'], ['fc6x'])\n",
      "(33, 'fc7', 'dagnn.Conv', ['fc6x'], ['fc7'])\n",
      "(34, 'relu7', 'dagnn.ReLU', ['fc7'], ['fc7x'])\n",
      "(35, 'score_fr', 'dagnn.Conv', ['fc7x'], ['score'])\n",
      "(36, 'score2', 'dagnn.ConvTranspose', ['score'], ['score2'])\n",
      "(37, 'score_pool4', 'dagnn.Conv', ['pool4'], ['score_pool4'])\n",
      "(38, 'crop', 'dagnn.Crop', ['score_pool4', 'score2'], ['score_pool4c'])\n",
      "(39, 'fuse', 'dagnn.Sum', ['score2', 'score_pool4c'], ['score_fused'])\n",
      "(40, 'upsample_new', 'dagnn.ConvTranspose', ['score_fused'], ['bigscore'])\n",
      "(41, 'cropx', 'dagnn.Crop', ['bigscore', 'data'], ['upscore'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(l.shape[1]):\n",
    "    print(i,\n",
    "          str(l[0,i].name[0]), str(l[0,i].type[0]),\n",
    "          [str(n[0]) for n in l[0,i].inputs[0,:]],\n",
    "          [str(n[0]) for n in l[0,i].outputs[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documentation for the dagnn.Crop layer :\n",
    "# https://github.com/vlfeat/matconvnet/blob/master/matlab/%2Bdagnn/Crop.m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Convolutional Networks for Semantic Segmentation\n",
    "##### Jonathan Long, Evan Shelhamer, Trevor Darrell\n",
    "\n",
    "www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf\n",
    "\n",
    "Extract from the article relating to the model architecture.\n",
    "\n",
    "The model is derived from VGG16.\n",
    "\n",
    "**remark** : deconvolution and conv-transpose are synonyms, they perform up-sampling\n",
    "\n",
    "#### 4.1. From classifier to dense FCN\n",
    "\n",
    "We decapitate each net by discarding the final classifier layer [**code comment** : *this is why fc8 is not included*], and convert all fully connected layers to convolutions.\n",
    "\n",
    "We append a 1x1 convolution with channel dimension 21 [**code comment** : *layer named score_fr*] to predict scores for each of the PASCAL classes (including background) at each of the coarse output locations, followed by a deconvolution layer to bilinearly upsample the coarse outputs to pixel-dense outputs as described in Section 3.3.\n",
    "\n",
    "\n",
    "#### 4.2. Combining what and where\n",
    "We define a new fully convolutional net (FCN) for segmentation that combines layers of the feature hierarchy and\n",
    "refines the spatial precision of the output.\n",
    "While fully convolutionalized classifiers can be fine-tuned to segmentation as shown in 4.1, and even score highly on the standard metric, their output is dissatisfyingly coarse.\n",
    "The 32 pixel stride at the final prediction layer limits the scale of detail in the upsampled output.\n",
    "\n",
    "We address this by adding skips that combine the final prediction layer with lower layers with finer strides.\n",
    "This turns a line topology into a DAG [**code comment** : *this is why some latter stage layers have 2 inputs*], with edges that skip ahead from lower layers to higher ones.\n",
    "As they see fewer pixels, the finer scale predictions should need fewer layers, so it makes sense to make them from shallower net outputs.\n",
    "Combining fine layers and coarse layers lets the model make local predictions that respect global structure.\n",
    "\n",
    "We first divide the output stride in half by predicting from a 16 pixel stride layer.\n",
    "We add a 1x1 convolution layer on top of pool4 [**code comment** : *the score_pool4_filter layer*] to produce additional class predictions.\n",
    "We fuse this output with the predictions computed on top of conv7 (convolutionalized fc7) at stride 32 by adding a 2x upsampling layer and summing [**code comment** : *layer named sum*] both predictions [**code warning** : *requires first layer crop to insure the same size*].\n",
    "\n",
    "Finally, the stride 16 predictions are upsampled back to the image [**code comment** : *layer named upsample_new*].\n",
    "\n",
    "We call this net FCN-16s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : adapt this function\n",
    "def weight_compare(kmodel):\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    prmt = (3,2,0,1) # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        mattype = l[0,i][0,0].type[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            print matname, mattype\n",
    "            print l[0,i][0,0].weights[0,0].transpose(prmt).shape, l[0,i][0,0].weights[0,1].shape\n",
    "            print kmodel.layers[kindex].get_weights()[0].shape, kmodel.layers[kindex].get_weights()[1].shape\n",
    "            print '------------------------------------------'\n",
    "        else:\n",
    "            print 'MISSING : ', matname, mattype\n",
    "            print '------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weight_compare(segmentmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : adapt this function\n",
    "def copy_mat_to_keras(kmodel):\n",
    "\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    prmt = (3,2,0,1) # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "\n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            #print matname\n",
    "            l_weights = l[0,i][0,0].weights[0,0]\n",
    "            l_bias = l[0,i][0,0].weights[0,1]\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            f_l_weights = np.flip(f_l_weights, 2)\n",
    "            f_l_weights = np.flip(f_l_weights, 3)\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])\n",
    "            #print '------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy_mat_to_keras(segmentmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
