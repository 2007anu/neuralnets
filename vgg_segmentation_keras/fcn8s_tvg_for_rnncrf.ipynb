{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import skimage.io as io\n",
    "from scipy.misc import bytescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Deconvolution2D, Cropping2D\n",
    "from keras.layers import merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING : this code is still far from being complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Random Fields as Recurrent Neural Networks\n",
    "#### Torr Vision Group\n",
    "##### Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su\n",
    "##### Dalong Du, Chang Huang, Philip H. S. Torr\n",
    "\n",
    "http://www.robots.ox.ac.uk/~szheng/papers/CRFasRNN.pdf\n",
    "\n",
    "### WARNING :\n",
    "#### In v1 of this script we will only implement the FCN-8s subcomponent of the CRF-RNN network\n",
    "\n",
    "#### Quotes from MatConvNet page (http://www.vlfeat.org/matconvnet/pretrained/#semantic-segmentation) :\n",
    "*These networks are trained on the PASCAL VOC 2011 training and (in part) validation data, using Berekely's extended annotations, as well as Microsoft COCO.*\n",
    "\n",
    "*While the CRF component is missing (it may come later to MatConvNet), this model still outperforms the FCN-8s network above, partially because it is trained with additional data from COCO.*\n",
    "\n",
    "*The model was obtained by first fine-tuning the plain FCN-32s network (without the CRF-RNN part) on COCO data, then building built an FCN-8s network with the learnt weights, and finally training the CRF-RNN network end-to-end using VOC 2012 training data only. The model available here is the FCN-8s part of this network (without CRF-RNN, while trained with 10 iterations CRF-RNN).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        if False:\n",
    "            # first version I tried\n",
    "            L.append( ZeroPadding2D((1, 1)) )\n",
    "            L.append( Convolution2D(cdim, 3, 3, activation='relu', name=convname) )\n",
    "        else:\n",
    "            L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) )\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fcn32_blank():\n",
    "    \n",
    "    withDO = False # no effect during evaluation but usefull for fine-tuning\n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        #mdl.add( Permute((1,2,3), input_shape=(3,224,224)) ) # WARNING : 0 is the sample dim\n",
    "        mdl.add( Permute((1,2,3), input_shape=(3,512,512)) ) # WARNING : 0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        mdl.add( Convolution2D(4096, 7, 7, border_mode='same', activation='relu', name='fc6') ) # WARNING border\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        mdl.add( Convolution2D(4096, 1, 1, border_mode='same', activation='relu', name='fc7') ) # WARNING border\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        \n",
    "        # WARNING : model decapitation i.e. remove the classifier step of VGG16 (usually named fc8)\n",
    "        \n",
    "        mdl.add( Convolution2D(21, 1, 1,\n",
    "                               border_mode='same', # WARNING : zero or same ? does not matter for 1x1\n",
    "                               activation='relu', name='score_fr') )\n",
    "        \n",
    "        mdl.add( Deconvolution2D(21, 4, 4, # WARNING : exact meaning ?\n",
    "                                 output_shape=(None, 21, 34, 34), # WARNING : exact meaning ?\n",
    "                                 subsample=(2, 2), # WARNING : exact meaning ?\n",
    "                                 border_mode='valid', # WARNING : valid, same or full ?\n",
    "                                 activation=None,\n",
    "                                 name = 'score2') )\n",
    "        \n",
    "        mdl.add( Cropping2D(cropping=((1, 1), (1, 1))) ) # WARNING : cropping as deconv gained pixels\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        # See following link for a version based on Keras functional API :\n",
    "        # gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WARNING : explanation about Deconvolution2D layer\n",
    "# http://stackoverflow.com/questions/39018767/deconvolution2d-layer-in-keras\n",
    "# the code example in the help (??Deconvolution2D) is very usefull too\n",
    "\n",
    "#?? Deconvolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fcn32model = fcn32_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fcn32model.summary() # visual inspection of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp4 = Convolution2D(21, 1, 1,\n",
    "                    border_mode='same', # WARNING : zero or same ? does not matter for 1x1\n",
    "                    activation=None, # WARNING : to check\n",
    "                    name='score_pool4')\n",
    "\n",
    "# INFO : to replicate MatConvNet.DAGN.Sum layer see documentation at :\n",
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "summed = merge([sp4(fcn32model.layers[14].output), fcn32model.layers[-1].output], mode='sum')\n",
    "\n",
    "# INFO : final 16x16 upsampling of \"summed\" using deconv layer upsample_new (32, 32, 21, 21)\n",
    "upnew = Deconvolution2D(21, 32, 32, # WARNING : exact meaning ?\n",
    "                        output_shape=(None, 21, 528, 528), # WARNING : exact meaning ?\n",
    "                        border_mode='valid', # WARNING : valid, same or full ?\n",
    "                        subsample=(16, 16),\n",
    "                        activation=None,\n",
    "                        name = 'upsample_new')\n",
    "\n",
    "crop8 = Cropping2D(cropping=((8, 8), (8, 8))) # WARNING : cropping as deconv gained pixels\n",
    "\n",
    "fcn16model = Model(fcn32model.input, crop8(upnew(summed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 21, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING : check dim weights against .mat file to check deconvolution setting\n",
    "upnew.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "permute_input_1 (InputLayer)     (None, 3, 512, 512)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 3, 512, 512)   0           permute_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Convolution2D)          (None, 64, 512, 512)  1792        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Convolution2D)          (None, 64, 512, 512)  36928       conv1_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 64, 256, 256)  0           conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Convolution2D)          (None, 128, 256, 256) 73856       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Convolution2D)          (None, 128, 256, 256) 147584      conv2_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 128, 128, 128) 0           conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Convolution2D)          (None, 256, 128, 128) 295168      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Convolution2D)          (None, 256, 128, 128) 590080      conv3_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3 (Convolution2D)          (None, 256, 128, 128) 590080      conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 64, 64)   0           conv3_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Convolution2D)          (None, 512, 64, 64)   1180160     maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Convolution2D)          (None, 512, 64, 64)   2359808     conv4_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3 (Convolution2D)          (None, 512, 64, 64)   2359808     conv4_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 512, 32, 32)   0           conv4_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Convolution2D)          (None, 512, 32, 32)   2359808     maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Convolution2D)          (None, 512, 32, 32)   2359808     conv5_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3 (Convolution2D)          (None, 512, 32, 32)   2359808     conv5_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 512, 16, 16)   0           conv5_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc6 (Convolution2D)              (None, 4096, 16, 16)  102764544   maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "fc7 (Convolution2D)              (None, 4096, 16, 16)  16781312    fc6[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "score_fr (Convolution2D)         (None, 21, 16, 16)    86037       fc7[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "score2 (Deconvolution2D)         (None, 21, 34, 34)    7077        score_fr[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "score_pool4 (Convolution2D)      (None, 21, 32, 32)    10773       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)        (None, 21, 32, 32)    0           score2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 21, 32, 32)    0           score_pool4[0][0]                \n",
      "                                                                   cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "upsample_new (Deconvolution2D)   (None, 21, 528, 528)  451605      merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)        (None, 21, 512, 512)  0           upsample_new[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 134,816,036\n",
      "Trainable params: 134,816,036\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcn16model.summary() # visual inspection of model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG weigths from .mat file\n",
    "\n",
    "#### https://www.vlfeat.org/matconvnet/pretrained/#semantic-segmentation\n",
    "##### Download from console with :\n",
    "wget http://www.vlfeat.org/matconvnet/models/pascal-fcn8s-tvg-dag.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = loadmat('pascal-fcn8s-tvg-dag.mat', matlab_compatible=False, struct_as_record=False)\n",
    "l = data['layers']\n",
    "p = data['params']\n",
    "description = data['meta'][0,0].classes[0,0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 46), (1, 40), (1, 21))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape, p.shape, description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeroplane', 'background', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n"
     ]
    }
   ],
   "source": [
    "class2index = {}\n",
    "for i, clname in enumerate(description[0,:]):\n",
    "    class2index[str(clname[0])] = i\n",
    "    \n",
    "print(sorted(class2index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False: # inspection of data structure\n",
    "    print(dir(l[0,31].block[0,0]))\n",
    "    print(dir(l[0,36].block[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'conv1_1f', (3, 3, 3, 64), 'conv1_1b', (64, 1))\n",
      "(2, 'conv1_2f', (3, 3, 64, 64), 'conv1_2b', (64, 1))\n",
      "(4, 'conv2_1f', (3, 3, 64, 128), 'conv2_1b', (128, 1))\n",
      "(6, 'conv2_2f', (3, 3, 128, 128), 'conv2_2b', (128, 1))\n",
      "(8, 'conv3_1f', (3, 3, 128, 256), 'conv3_1b', (256, 1))\n",
      "(10, 'conv3_2f', (3, 3, 256, 256), 'conv3_2b', (256, 1))\n",
      "(12, 'conv3_3f', (3, 3, 256, 256), 'conv3_3b', (256, 1))\n",
      "(14, 'conv4_1f', (3, 3, 256, 512), 'conv4_1b', (512, 1))\n",
      "(16, 'conv4_2f', (3, 3, 512, 512), 'conv4_2b', (512, 1))\n",
      "(18, 'conv4_3f', (3, 3, 512, 512), 'conv4_3b', (512, 1))\n",
      "(20, 'conv5_1f', (3, 3, 512, 512), 'conv5_1b', (512, 1))\n",
      "(22, 'conv5_2f', (3, 3, 512, 512), 'conv5_2b', (512, 1))\n",
      "(24, 'conv5_3f', (3, 3, 512, 512), 'conv5_3b', (512, 1))\n",
      "(26, 'fc6f', (7, 7, 512, 4096), 'fc6b', (4096, 1))\n",
      "(28, 'fc7f', (1, 1, 4096, 4096), 'fc7b', (4096, 1))\n",
      "(30, 'score_frf', (1, 1, 4096, 21), 'score_frb', (21, 1))\n",
      "(32, 'score2f', (4, 4, 21, 21), 'score2b', (21, 1))\n",
      "(34, 'score_pool4f', (1, 1, 512, 21), 'score_pool4b', (21, 1))\n",
      "(36, 'score4f', (4, 4, 21, 21), 'score_pool3f', (1, 1, 256, 21))\n",
      "(38, 'score_pool3b', (21, 1), 'upsamplef', (16, 16, 21, 21))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, p.shape[1]-1, 2):\n",
    "    print(i,\n",
    "          str(p[0,i].name[0]), p[0,i].value.shape,\n",
    "          str(p[0,i+1].name[0]), p[0,i+1].value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'conv1_1', 'dagnn.Conv', ['data'], ['conv1_1'])\n",
      "(1, 'relu1_1', 'dagnn.ReLU', ['conv1_1'], ['conv1_1x'])\n",
      "(2, 'conv1_2', 'dagnn.Conv', ['conv1_1x'], ['conv1_2'])\n",
      "(3, 'relu1_2', 'dagnn.ReLU', ['conv1_2'], ['conv1_2x'])\n",
      "(4, 'pool1', 'dagnn.Pooling', ['conv1_2x'], ['pool1'])\n",
      "(5, 'conv2_1', 'dagnn.Conv', ['pool1'], ['conv2_1'])\n",
      "(6, 'relu2_1', 'dagnn.ReLU', ['conv2_1'], ['conv2_1x'])\n",
      "(7, 'conv2_2', 'dagnn.Conv', ['conv2_1x'], ['conv2_2'])\n",
      "(8, 'relu2_2', 'dagnn.ReLU', ['conv2_2'], ['conv2_2x'])\n",
      "(9, 'pool2', 'dagnn.Pooling', ['conv2_2x'], ['pool2'])\n",
      "(10, 'conv3_1', 'dagnn.Conv', ['pool2'], ['conv3_1'])\n",
      "(11, 'relu3_1', 'dagnn.ReLU', ['conv3_1'], ['conv3_1x'])\n",
      "(12, 'conv3_2', 'dagnn.Conv', ['conv3_1x'], ['conv3_2'])\n",
      "(13, 'relu3_2', 'dagnn.ReLU', ['conv3_2'], ['conv3_2x'])\n",
      "(14, 'conv3_3', 'dagnn.Conv', ['conv3_2x'], ['conv3_3'])\n",
      "(15, 'relu3_3', 'dagnn.ReLU', ['conv3_3'], ['conv3_3x'])\n",
      "(16, 'pool3', 'dagnn.Pooling', ['conv3_3x'], ['pool3'])\n",
      "(17, 'conv4_1', 'dagnn.Conv', ['pool3'], ['conv4_1'])\n",
      "(18, 'relu4_1', 'dagnn.ReLU', ['conv4_1'], ['conv4_1x'])\n",
      "(19, 'conv4_2', 'dagnn.Conv', ['conv4_1x'], ['conv4_2'])\n",
      "(20, 'relu4_2', 'dagnn.ReLU', ['conv4_2'], ['conv4_2x'])\n",
      "(21, 'conv4_3', 'dagnn.Conv', ['conv4_2x'], ['conv4_3'])\n",
      "(22, 'relu4_3', 'dagnn.ReLU', ['conv4_3'], ['conv4_3x'])\n",
      "(23, 'pool4', 'dagnn.Pooling', ['conv4_3x'], ['pool4'])\n",
      "(24, 'conv5_1', 'dagnn.Conv', ['pool4'], ['conv5_1'])\n",
      "(25, 'relu5_1', 'dagnn.ReLU', ['conv5_1'], ['conv5_1x'])\n",
      "(26, 'conv5_2', 'dagnn.Conv', ['conv5_1x'], ['conv5_2'])\n",
      "(27, 'relu5_2', 'dagnn.ReLU', ['conv5_2'], ['conv5_2x'])\n",
      "(28, 'conv5_3', 'dagnn.Conv', ['conv5_2x'], ['conv5_3'])\n",
      "(29, 'relu5_3', 'dagnn.ReLU', ['conv5_3'], ['conv5_3x'])\n",
      "(30, 'pool5', 'dagnn.Pooling', ['conv5_3x'], ['pool5'])\n",
      "(31, 'fc6', 'dagnn.Conv', ['pool5'], ['fc6'])\n",
      "(32, 'relu6', 'dagnn.ReLU', ['fc6'], ['fc6x'])\n",
      "(33, 'fc7', 'dagnn.Conv', ['fc6x'], ['fc7'])\n",
      "(34, 'relu7', 'dagnn.ReLU', ['fc7'], ['fc7x'])\n",
      "(35, 'score_fr', 'dagnn.Conv', ['fc7x'], ['score'])\n",
      "(36, 'score2', 'dagnn.ConvTranspose', ['score'], ['score2'])\n",
      "(37, 'score_pool4', 'dagnn.Conv', ['pool4'], ['score_pool4'])\n",
      "(38, 'crop', 'dagnn.Crop', ['score_pool4', 'score2'], ['score_pool4c'])\n",
      "(39, 'fuse', 'dagnn.Sum', ['score2', 'score_pool4c'], ['score_fused'])\n",
      "(40, 'score4', 'dagnn.ConvTranspose', ['score_fused'], ['score4'])\n",
      "(41, 'score_pool3', 'dagnn.Conv', ['pool3'], ['score_pool3'])\n",
      "(42, 'cropx', 'dagnn.Crop', ['score_pool3', 'score4'], ['score_pool3c'])\n",
      "(43, 'fusex', 'dagnn.Sum', ['score4', 'score_pool3c'], ['score_final'])\n",
      "(44, 'upsample', 'dagnn.ConvTranspose', ['score_final'], ['bigscore'])\n",
      "(45, 'cropxx', 'dagnn.Crop', ['bigscore', 'data'], ['coarse'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(l.shape[1]):\n",
    "    print(i,\n",
    "          str(l[0,i].name[0]), str(l[0,i].type[0]),\n",
    "          [str(n[0]) for n in l[0,i].inputs[0,:]],\n",
    "          [str(n[0]) for n in l[0,i].outputs[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documentation for the dagnn.Crop layer :\n",
    "# https://github.com/vlfeat/matconvnet/blob/master/matlab/%2Bdagnn/Crop.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def copy_mat_to_keras(kmodel):\n",
    "    \n",
    "    raise ValueError('need to be adapted')\n",
    "    \n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "\n",
    "    prmt = (3,2,0,1) # WARNING : important setting as 2 of the 4 axis have same size dimension\n",
    "    \n",
    "    for i in range(0, p.shape[1]-1, 2):\n",
    "        matname = '_'.join(p[0,i].name[0].split('_')[0:-1])\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            print 'found : ', (str(matname), kindex)\n",
    "            l_weights = p[0,i].value\n",
    "            l_bias = p[0,i+1].value\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            f_l_weights = np.flip(f_l_weights, 2)\n",
    "            f_l_weights = np.flip(f_l_weights, 3)\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])\n",
    "        else:\n",
    "            print 'not found : ', str(matname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need to be adapted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-64c2bd7db9b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#copy_mat_to_keras(fcn32model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcopy_mat_to_keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfcn16model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-89f5c8d356e2>\u001b[0m in \u001b[0;36mcopy_mat_to_keras\u001b[1;34m(kmodel)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcopy_mat_to_keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'need to be adapted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mkerasnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need to be adapted"
     ]
    }
   ],
   "source": [
    "#copy_mat_to_keras(fcn32model)\n",
    "copy_mat_to_keras(fcn16model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
