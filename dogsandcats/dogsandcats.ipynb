{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Rather than importing everything manually, we'll make things easy\n",
    "#   and load them all in utils.py, and just import them from there.\n",
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path = \"data/dogscats/sample/\"\n",
    "path = \"\"\n",
    "model_path = path + \"models/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_8 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 224, 224)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()\n",
    "#model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 21000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use batch size of 1 since we're just doing preprocessing on the CPU\n",
    "val_batches = get_batches('valid', shuffle=True, batch_size=batch_size)\n",
    "trn_batches = get_batches('train', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#val_data = get_data(val_batches)\n",
    "#trn_data = get_data(trn_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.predict(val_batches, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imgs, labels = next(trn_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vgg.predict(imgs, True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.pop()\n",
    "for layer in vgg.model.layers:\n",
    "    layer.trainable=False\n",
    "vgg.model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.0005)\n",
    "vgg.model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.fit_generator(trn_batches, samples_per_epoch=trn_batches.N, nb_epoch=1, validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.0020906650461256504, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(0.007886412553489208, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(1.2159348727891484e-07, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(0.5502254366874695, dtype=float32), array(0.9599999785423279, dtype=float32)]\n",
      "[array(1.358986168042975e-07, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(0.16351263225078583, dtype=float32), array(0.9800000190734863, dtype=float32)]\n",
      "[array(0.00029040570370852947, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(0.0001684165035840124, dtype=float32), array(1.0, dtype=float32)]\n",
      "[array(0.5389044284820557, dtype=float32), array(0.9399999976158142, dtype=float32)]\n",
      "[array(0.3258085548877716, dtype=float32), array(0.9800000190734863, dtype=float32)]\n",
      "------\n",
      "[array(0.025226211175322533, dtype=float32), array(0.9800000190734863, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    imgs, labels = next(trn_batches)\n",
    "    o = vgg.model.train_on_batch(imgs, labels)\n",
    "    print(o)\n",
    "\n",
    "print('------')\n",
    "imgs, labels = next(val_batches)\n",
    "ov = vgg.model.test_on_batch(imgs, labels)\n",
    "print(ov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "21000/21000 [==============================] - 661s - loss: 0.2105 - acc: 0.9800 - val_loss: 0.1585 - val_acc: 0.9843\n"
     ]
    }
   ],
   "source": [
    "vgg.fit(trn_batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.save_weights(model_path+'finetune1.h5')\n",
    "#vgg.model.load_weights(model_path+'finetune1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test/10592.jpg',\n",
       " 'test/7217.jpg',\n",
       " 'test/3653.jpg',\n",
       " 'test/4382.jpg',\n",
       " 'test/2924.jpg',\n",
       " 'test/10.jpg',\n",
       " 'test/10916.jpg',\n",
       " 'test/12374.jpg',\n",
       " 'test/1871.jpg',\n",
       " 'test/11645.jpg']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches = get_batches('test', shuffle=False, batch_size=100, class_mode=None)\n",
    "#gen = image.ImageDataGenerator()\n",
    "#test_batches = gen.flow_from_directory(\"test\", target_size=(224,224), class_mode=None, shuffle=False, batch_size=50)\n",
    "test_preds = []\n",
    "testfiles = test_batches.filenames\n",
    "testfiles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    imgs = next(test_batches)\n",
    "    bps = vgg.model.predict_on_batch(imgs).tolist()\n",
    "    test_preds.extend(bps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.471363387541058e-43],\n",
       " [1.0, 0.0],\n",
       " [9.274744774610854e-37, 1.0],\n",
       " [1.0, 1.8135492388597416e-18],\n",
       " [6.925395368284626e-09, 1.0],\n",
       " [1.0, 0.0],\n",
       " [5.914161881561224e-18, 1.0],\n",
       " [1.0, 0.0],\n",
       " [9.36502665811189e-34, 1.0],\n",
       " [0.0, 1.0]]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'label': 0.9999},\n",
       " {'id': 2, 'label': 0.9999},\n",
       " {'id': 3, 'label': 0.9999},\n",
       " {'id': 4, 'label': 0.9999},\n",
       " {'id': 5, 'label': 0.0001},\n",
       " {'id': 6, 'label': 0.0001},\n",
       " {'id': 7, 'label': 0.0001},\n",
       " {'id': 8, 'label': 0.0001},\n",
       " {'id': 9, 'label': 0.0001},\n",
       " {'id': 10, 'label': 0.0001},\n",
       " {'id': 11, 'label': 0.0001},\n",
       " {'id': 12, 'label': 0.9999},\n",
       " {'id': 13, 'label': 0.0001},\n",
       " {'id': 14, 'label': 0.0001},\n",
       " {'id': 15, 'label': 0.0001},\n",
       " {'id': 16, 'label': 0.0001},\n",
       " {'id': 17, 'label': 0.9999},\n",
       " {'id': 18, 'label': 0.9999}]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z0 = [{'id':int(f.split('/')[-1].split('.')[0]), 'label':min(max(round(p[0],5),0.0001),0.9999)} for f, p in zip(testfiles, test_preds)]\n",
    "Z1 = [{'id':int(f.split('/')[-1].split('.')[0]), 'label':min(max(round(p[1],5),0.0001),0.9999)} for f, p in zip(testfiles, test_preds)]\n",
    "def comp(x,y):\n",
    "    return int(x['id']) - int(y['id'])\n",
    "Z0 = sorted(Z0, comp)\n",
    "Z1 = sorted(Z1, comp)\n",
    "Z1[0:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('predictions_0.csv', 'w') as csvfile:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for z in Z0:\n",
    "        writer.writerow(z)\n",
    "        \n",
    "with open('predictions_1.csv', 'w') as csvfile:\n",
    "    fieldnames = ['id', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for z in Z1:\n",
    "        writer.writerow(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
